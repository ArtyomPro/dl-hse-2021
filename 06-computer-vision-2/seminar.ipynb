{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обратная связь\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Почему мы начали с картинок?\n",
    "\n",
    "> Рассказать про применение сетей не только в компьютерном зрении <...>\n",
    "Многие студенты <...> не занимаются на прямую компьютерным зрением, а планируют использовать глубинное обучение для анализа табличных данных или, например, данных на графах.\n",
    "\n",
    "Короткий ответ:\n",
    "- не используйте DL для табличек\n",
    "\n",
    "Длинный ответ:\n",
    "- другие области (тексты, аудио, ряды и немного графы) мы тоже разберем!\n",
    "- у вас есть подходящая интуиция\n",
    "- визуализируемые представления\n",
    "- наиболее развитая область: приемы и инструменты сначала обкатывают здесь, потом переносят куда-то еще\n",
    "- хорошие датасеты и понятные задачи\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "### Про предопределенность и основы\n",
    "\n",
    "> Знакомство с базовыми слоями PyTorch <...> на эти штуки порой отводится несколько полноценных семинаров.\n",
    "Насколько я понимаю понятно, что структура домашек и тд уже составлена, мой коммент не имеет особого смысла : )\n",
    "\n",
    "\n",
    "1. Про базовые слои PT можно провести отдельное занятие, но ...\n",
    "\n",
    "2. Нет структура домашек заранее не фиксирована: у нас есть набор вещей, которые мы хотим рассказать, что-то идет в домашки, что-то в семинар. Мы открыты к предложениям.\n",
    "\n",
    "\n",
    "\n",
    "### Про непонятки\n",
    "\n",
    "> Прохожу курс по DL с нуля. Очень много вещей не понял на лекции. Сейчас смотрю базовый курс по DL от вышки, чтобы вникнуть\n",
    "\n",
    "**Это не ваш недостаток.**\n",
    "\n",
    "Не стесняйтесь, пишите в общий чат.\n",
    "\n",
    "Мы можем выделить занятие на подробное объяснение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision part 2\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m12sl/dl-hse-2021/blob/master/06-computer-vision-2/seminar.ipynb)\n",
    "\n",
    "\n",
    "- How to get grads w.r.t. inputs?\n",
    "- Naive Adversarial Attacks\n",
    "- FGSM\n",
    "- Let's make creappy images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import json\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "with open(\"imagenet_1k.json\") as fin:\n",
    "    idx2cls = {int(k): v for k, v in json.load(fin).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заготовим картинку чтобы была\n",
    "! wget https://sobakibalabaki.com/wp-content/uploads/2017/06/dog-and-horsejpg.jpg -O doge-and-horsy.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предварительная подготовка\n",
    "\n",
    "Нам потребуется конвертить картинки в тензора и обратно\n",
    "\n",
    "\n",
    "```\n",
    "    mean = np.array([0.485, 0.456, 0.406]).reshape(1,1,3)\n",
    "    std =  np.array([0.229, 0.224, 0.225]).reshape(1,1,3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uint2tv(x, channel_dim=-1):\n",
    "    assert x.shape[channel_dim] == 3, f\"Wrong shape\"\n",
    "    return x\n",
    "\n",
    "\n",
    "def tv2uint(x, channel_dim=-1):\n",
    "    assert x.shape[channel_dim] == 3, f\"Wrong shape\"\n",
    "    return x\n",
    "\n",
    "\n",
    "def load(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = cv2.resize(img, (300, 210))  \n",
    "    x = uint2tv(img)\n",
    "    print(x.shape)\n",
    "    img = np.transpose(x, [2, 0, 1])[None, ...]\n",
    "    img = torch.tensor(img)\n",
    "    # [1, 3, w, h]\n",
    "    return img\n",
    "\n",
    "\n",
    "tt = load(\"./doge-and-horsy.jpg\")\n",
    "\n",
    "x = tv2uint(tt.numpy(), channel_dim=1)\n",
    "print(x.shape)\n",
    "x = np.transpose(x[0, ...], [1, 2, 0])\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте код для сохранения интересных нам активаций во время прямого прохода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeryWrapper(nn.Module):\n",
    "    def __init__(self, model, layer_of_interest=None):\n",
    "        super().__init__()\n",
    "        self.model = model        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "net = torchvision.models.resnet50(pretrained=True)\n",
    "net = net.eval()\n",
    "model = VeryWrapper(net)\n",
    "\n",
    "horse = load(\"./doge-and-horsy.jpg\")\n",
    "\n",
    "y = model(horse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивная атака градиентным спуском\n",
    "\n",
    "Давайте оптимизировать входную картинку так, чтобы изменить результат работы сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_attack(init_tensor, target, num_iters=50, epsilon=1e-5):\n",
    "    x = init_tensor.clone().detach()\n",
    "    x.requires_grad = True\n",
    "    <todo>\n",
    "    \n",
    "        \n",
    "img = load(\"./doge-and-horsy.jpg\")\n",
    "naive_attack(img, 0, epsilon=100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картинка должна остаться картинкой!\n",
    "Это означает, что изменения должны пережить переход из fp32 -> uin8.\n",
    "\n",
    "Как этого добиться?\n",
    "\n",
    "Напишите тесты на преодоление air-gap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uint8_test(original, img, net):\n",
    "    pass\n",
    "\n",
    "def jpeg_compression_test(original, img, net):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM\n",
    "\n",
    "Используем вместо градиентов знак градиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(init_tensor, target, num_iters=50, epsilon=0.01):\n",
    "    x = init_tensor.clone().detach()\n",
    "    x.requires_grad = True\n",
    "    <todo>\n",
    "\n",
    "        \n",
    "img = load(\"./doge-and-horsy.jpg\")\n",
    "fsgm_attack(img, 0, epsilon=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем странные картинки\n",
    "\n",
    "Что если оптимизировать не CE, а величину активации какого-нибудь слоя или нейрона?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "<todo>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
