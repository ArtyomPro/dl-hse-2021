{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика обучения моделей 2\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m12sl/dl-hse-2021/blob/master/03-training/seminar.ipynb)\n",
    "\n",
    "\n",
    "План семинара:\n",
    "\n",
    "- [ ] Освоить LR scheduling\n",
    "- [ ] Написать LR range test\n",
    "- [ ] Разобраться с подсчетом валидационных и тренировочных метрик \n",
    "- [ ] Classier Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Scheduling\n",
    "\n",
    "Два типа расписаний:\n",
    "\n",
    "- по эпохам (StepLR, ReduceLROnPlateau, ...) \n",
    "    ```\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        train(...)\n",
    "        validate(...)\n",
    "        scheduler.step()\n",
    "    ```\n",
    "\n",
    "\n",
    "- по батчам (Cosine, Cyclic, 1cycle, ...)\n",
    "    ```\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        # train(...)\n",
    "        for batch in data_loader:\n",
    "            train_batch(...)\n",
    "            scheduler.step()\n",
    "        # validate(...)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор оптимального LR\n",
    "\n",
    "\n",
    "Для выбора оптимального LR удобно использовать т.н. Learning Rate Range Test, часто процедуру называют просто find_lr. Под капотом проход по тренировочной эпохе с lr, изменяемым на каждом батче по формуле:\n",
    "\n",
    "$$\n",
    "\\mathrm{it} = \\frac{\\mathrm{step}}{\\mathrm{total steps}}\\\\\n",
    "\\mathrm{lr} = \\exp\\left\\{ \n",
    "    (1 - t ) \\log a + t \\log b\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "Чтобы поменять LR для всех оптимизируемых параметров, можно пройтись по ним циклом:\n",
    "\n",
    "```\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = lr\n",
    "```\n",
    "\n",
    "\n",
    "<img src=\"https://www.jeremyjordan.me/content/images/2018/02/lr_finder.png\"/>\n",
    "\n",
    "_картинка из бложика [Jeremy Jordan](https://www.jeremyjordan.me/nn-learning-rate/)_\n",
    "\n",
    "\n",
    "Идея приема простая: пока LR меньше некоторого порога на каждом шаге градиентного спуска веса просто не меняются (в частности из-за особенностей операций с плавающей точкой).\n",
    "При очень большом LR мы шагаем слишком далеко и уходим от точки экстремума. \n",
    "\n",
    "Оптимальный LR лежит где-то между ними. Экспоненциальная формула изменения LR позволяет с должным качеством найти хорошую точку.\n",
    "\n",
    "\n",
    "\n",
    "Если интересно: [статья , в которой эту технику предложили и активно использовали](https://arxiv.org/pdf/1506.01186.pdf).\n",
    "\n",
    "\n",
    "**Some math notes**\n",
    "\n",
    "У типов данных с плавающей точкой есть арифметические особенности:\n",
    "\n",
    "$$\n",
    "# fp32\n",
    "x + \\delta == x,\\,\\mathrm{если}\\; \\delta < 5.96 \\cdot 10^{-8} x\n",
    "$$\n",
    "\n",
    "К слову, это еще одна причина присматривать за величинами активаций, нормировать данные и таргет в случае регрессии. Можно было бы перейти на float64, но (вычислительно и по памяти) дешевле быть аккуратными на float32.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://blogs.nvidia.com/wp-content/uploads/2020/05/tf32-Mantissa-chart-hi-res-FINAL-400x255.png.webp\"/>\n",
    "\n",
    "_картинка из статьи [NVIDIA](https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики\n",
    "\n",
    "TL; DR:\n",
    "- тренировочные метрики записывать без сглаживания с каждого батча\n",
    "- валидационные собирать за всю валидацию и рисовать одной точкой\n",
    "\n",
    "\n",
    "**Особенности TB**:\n",
    "\n",
    "- При отображении прореживает точки по global_step\n",
    "- Чтобы рисовать на одном графике надо писать в разные папки (завести отдельные train_ и val_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обновим Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
